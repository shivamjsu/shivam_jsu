{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6f1767",
   "metadata": {},
   "source": [
    " #### Model Building Steps\n",
    "    \n",
    "    1. Understanding the Bussiness problem\n",
    "    2. Loading and understanding the Data\n",
    "    3. Exploratory Data Analysis(EDA)\n",
    "        a.Descriptive Statistics\n",
    "        b.Data Visualization\n",
    "    4. Data PreProcessing\n",
    "        a.Identifiying Num and Cat data and converting them to appropriate dtype\n",
    "        b.Dectecting the outliers and removing.\n",
    "        c.Data Wrangling or Data cleaning(Imputation)\n",
    "                (only if more than 25% of the data is missing, or else remove those rows)\n",
    "    5. Model Building\n",
    "        a.Assining X and y status to attributes and target\n",
    "        b.creating dummies (or) perform label, onehotencoding for categorical attribute.    \n",
    "        c.Train-Test split.\n",
    "        d.Scaling(if required).\n",
    "        e.Training the Model.\n",
    "        f.Prediction on test data.\n",
    "    6. Evaluate the model with the appropriate Metrics.\n",
    "    7. Hyper parmeter tuning if required and updating the model.\n",
    "    8. Inference about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cc9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a4b22e6",
   "metadata": {},
   "source": [
    "## 1.UNDERSTANDING THE BUSSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5876edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b320d3f3",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651bfa0",
   "metadata": {},
   "source": [
    "## 2.COLLECTION AND LOADING THE DATA  \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a1c2944",
   "metadata": {},
   "source": [
    "    The better the collection of data, the better will be the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e906bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######Importing date from data directly as date format and making as index(for time series)\n",
    "\n",
    "data = pd.read_csv(\"TimeSeries.csv\",parse_dates=['Date'],index_col=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2a976",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01377c0",
   "metadata": {},
   "source": [
    "## 3.EXPLORATORY DATA ANALYSIS \n",
    "\t\t"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0a9911a",
   "metadata": {},
   "source": [
    "\tExploratory Data Analysis (EDA) is done in order to gain an understanding of the dataset. \n",
    "\n",
    "\tSome of the common approaches for EDA includes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45420408",
   "metadata": {},
   "source": [
    "###### Descriptive statistics – Mean, median, Standard deviation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90878e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3f695",
   "metadata": {},
   "source": [
    "###### Data visualization – Scatter plot, corelation heatmap, box plot, Count plot of target column(if categorical),etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e136a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "data.plot(kind='hist',subplots=True,layout=(3,3),sharex=False,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "data.plot(kind='box',subplots=True,layout=(3,3),sharex=False,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Correlation amongst numeric attributes using heatmap\n",
    "cmap = sns.diverging_palette(260,-10,s=50, l=75, n=6, as_cmap=True)\n",
    "plt.subplots(figsize=(18,18))\n",
    "sns.heatmap(data.corr(),cmap= cmap,annot=True, square=True)\n",
    "\n",
    "******************** or simply ****************************\n",
    "\n",
    "sns.heatmap(data.corr(),annot=True,cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the target and find out if our data is imbalanced or not by using countplot\n",
    "\n",
    "cols= [\"#C2C4E2\",\"#EED4E5\"]\n",
    "sns.countplot(x= data[\"RainTomorrow\"], palette= cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04feb1cb",
   "metadata": {},
   "source": [
    "*********************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226864db",
   "metadata": {},
   "source": [
    "## 4.DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04989aab",
   "metadata": {},
   "source": [
    "\tSteps involved in Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c258e9",
   "metadata": {},
   "source": [
    "### a) Identify categorical and numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in data.columns if data[col].dtype == 'object']\n",
    "num_cols  = [col for col in data.columns if data[col].dtype in['int64', 'float64']]\n",
    "\n",
    "# Get list of categorical variables and numerical variable\n",
    "\n",
    "o = (data.dtypes == \"object\")\n",
    "object_cols = list(o[o].index)\n",
    "\n",
    "n = (data.dtypes == \"float64\")\n",
    "num_cols = list(n[n].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)\n",
    "\n",
    "print(\"Numeric variables:\")\n",
    "print(num_cols)\n",
    "\n",
    "***********************      or       **********************\n",
    "\n",
    "num_attr = data.select_dtypes(['int64','float64']).columns\n",
    "num_attr\n",
    "\n",
    "cat_attr = data.select_dtypes('category').columns\n",
    "cat_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f914fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for cardinality(number of levels) in categorical variables\n",
    "for i in cat_attr:\n",
    "    print('**********************************************')\n",
    "    print('{0} contains {1} unique values'.format(i, data[i].nunique()))\n",
    "    print('\\n')\n",
    "    print(data[i].value_counts())\n",
    "\n",
    "for var in categorical:\n",
    "    print(var, ' contains ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check for the frequency Distribution of the target variable\n",
    "df.target.value_counts() # in numbers\n",
    "df.target.value_counts(normalize=True) # in percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8314e",
   "metadata": {},
   "source": [
    "### b) detecting and removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting outliers\n",
    "#looking at the scaled features\n",
    "colours = [\"#D0DBEE\", \"#C2C4E2\", \"#EED4E5\", \"#D1E6DC\", \"#BDE2E2\"]\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxenplot(data = features,palette = colours)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d45c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=np.quantile(data['column'],0.25)\n",
    "Q3=np.quantile(data['column'],0.75)\n",
    "IQR=Q3-Q1\n",
    "\n",
    "lower=Q1+1.5*IQR\n",
    "upper=Q3-1.5*IQR\n",
    "\n",
    "data=data.loc[(data['column']>lower) & (data['column']<upper),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2187ee1",
   "metadata": {},
   "source": [
    "### c) data wrangling or data cleaning.\n",
    "\t\tFilling missing values(imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d7c50",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90ff66",
   "metadata": {},
   "source": [
    "************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac32a7",
   "metadata": {},
   "source": [
    "###### ---->For categorical attributes:-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d0f9b",
   "metadata": {},
   "source": [
    "###### ----> Filling missing values  using 'for loop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values in categorical variables:\n",
    "\n",
    "data.isnull().sum()\n",
    " \n",
    "for i in cat_attr:\n",
    "    data[i].fillna(data[i].mode()[0], inplace=True)\n",
    "    \n",
    "\n",
    "# Filling missing values for numerical attrbutes by median\n",
    "for i in num_attr:\n",
    "    data[i].fillna(data[i].median()[0], inplace=True)\n",
    "    \n",
    "******************* or ******************************\n",
    "\n",
    "\n",
    "for df1 in [X_train, X_test]:\n",
    "    for col in numerical:\n",
    "        col_median=X_train[col].median()\n",
    "        df1[col].fillna(col_median, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bfce5",
   "metadata": {},
   "source": [
    "###### ---->Simple Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42971cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### for categorical attributes\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_cat= SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer_cat = imputer_cat.fit(X_train[cat_attr])\n",
    "\n",
    "X_train[cat_attr] = imputer_cat.transform(X_train[cat_attr])\n",
    "X_test[cat_attr] = imputer_cat.transform(X_test[cat_attr])\n",
    "\n",
    "********************* or *********************\n",
    "imputer_cat= SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer_cat = imputer_cat.fit_transform(data[cat_attr])\n",
    "# impute missing values in X_train and X_test with respective column median in X_train\n",
    "\n",
    "Imputing missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer = imputer.fit(X_train[num_attr])\n",
    "\n",
    "X_train[num_attr] = imputer.transform(X_train[num_attr])\n",
    "X_test[num_attr] = imputer.transform(X_test[num_attr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167a355",
   "metadata": {},
   "source": [
    "###### ---->TimeSeries imputation by interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c114dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price'] = data['Price'].interpolate(method='linear',limit_direction='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "**********************time series preprocessing**************************************\n",
    "\n",
    "#Aggregation of a variable containing duplicates with any arithematic operations\n",
    "\n",
    "agg_data = pd.DataFrame(data.groupby(['Year','Month'],as_index=False)['Price'].mean())\n",
    "\n",
    "#setting a variable as index \n",
    "\n",
    "data.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87690ae",
   "metadata": {},
   "source": [
    "***********************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customers.groupby('Gender').agg(['mean','min','max', 'std'])['Yearly Amount Spent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4da57",
   "metadata": {},
   "source": [
    "## 5.MODEL BUILDING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29299596",
   "metadata": {},
   "source": [
    "\tFollowing steps are involved in the model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe31630",
   "metadata": {},
   "source": [
    "###### a)Assining X and y the status of attributes and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.drop([\"y\"], axis=1)\n",
    "y = features[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename the target labels(np.where)\n",
    "#creating bins of numerical variable\n",
    "For <=50K replace them with 0 and for >50K replace them with 1.\n",
    "\n",
    "df_train.target = np.where(df_train['target']== '<=50K', 0, 1)\n",
    "df_test.target =  np.where(df_test['target']== '<=50K.', 0, 1)\n",
    "\n",
    "**************************** or *******************************\n",
    "\n",
    "df['y'] = df['y'].apply(lambda x: 0 if x.strip()=='no' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daec29",
   "metadata": {},
   "source": [
    "###### b) Creating dummies (or) perform label, onehotencoding for categorical attribute.\n",
    "###### ----> Lable encoding -----> If the column is ordinal eg: small / medium / large ==> 0 / 1 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for i in object_cols:\n",
    "    data[i] = label_encoder.fit_transform(data[i])\n",
    "    \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a7185",
   "metadata": {},
   "source": [
    "###### ----> One hot encoding -----> If there is no order in the data eg: state (Hyd/ Blr / Chn)-> Hyd(0/1) -> Blr (0/1) -> chn (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train_cat = pd.DataFrame(ohe.fit_transform(X_train[cat_cols]), columns = ohe.get_feature_names())\n",
    "X_test_cat = pd.DataFrame(ohe.transform(X_test[cat_cols]), columns = ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dc003",
   "metadata": {},
   "source": [
    "###### c)Splitting test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y,random_state=123)\n",
    "\n",
    "#when there is a class imbalance in the data the distribution of the class-imbalance will be \n",
    "#maintained in the Y_train ,Y_test split also.so that the training of the data will become more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0e3b1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338154770615466"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(scores))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc27cfda",
   "metadata": {},
   "source": [
    "\tOne more common approach is to split the data into 3 portions as training data, validation data, \n",
    "\tand testing data. As explained before, the training set is used to train the model, the validation     set is used for evaluation where model tuning (like hyperparameter tuning) is done. Th testing set     can be used to further test the model.\n",
    "\n",
    "\tCross-Validation\n",
    "\tIn order to use the data effectively, N-fold cross-validation is used in splitting the data.\n",
    "\tHere data is split into N folds. For example in a 10-fold CV, 2 folds are used for training and \n",
    "\tthe remaining 8 folds are used for the training phase. iteratively all the folds get interchanged \n",
    "\tsuch that every fold gets a chance to be testing data. So a total of 10 models can be built using \n",
    "\tthis can performance metrics values will be calculated for those models. And the final decision         will be made after analyzing the performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed8562",
   "metadata": {},
   "source": [
    "###### d)Perform the scaling of the features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bbf5780",
   "metadata": {},
   "source": [
    "Scaling, you're changing the range of your data, while\n",
    "Normalization, you're changing the shape of the distribution of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scaler for the features\n",
    "col_names=list(num_var)\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "data[num_attr] = s_scaler.fit_transform(data[num_var])\n",
    "\n",
    "# features = pd.DataFrame(features, columns=col_names) \n",
    "\n",
    "# features.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f06753",
   "metadata": {},
   "source": [
    "###### e)Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d32194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=cv)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "886bedc1",
   "metadata": {},
   "source": [
    "\tBias – They are the assumptions made by the model to make a function easy to learn\n",
    "    \n",
    "\tVariance – After training data and obtaining low error. Upon changing the data, \n",
    "\tthen training the same model and experiencing a high error, is known as variance. \n",
    "\n",
    "\tOverfitting and Underfitting\n",
    "\n",
    "\tA model is said to be under-fitted when it cannot capture the underlying data. \n",
    "\tIt denotes that our algorithm or model does not fit the data well. It happens when we have fewer \n",
    "\tdata to build the model. \n",
    "    Overfitting simply means high bias and low variance. Underfitting reduces\n",
    "\tthe accuracy of the model.\n",
    "\n",
    "\n",
    "\n",
    "\tUnderfitting can be reduced by\n",
    "\n",
    "\t*Increasing the model complexity\n",
    "\t*Increasing the number of features\n",
    "\t*Removing the noise from the data \n",
    "\t*Increasing the duration of training \n",
    "\n",
    "\tA model is said to be over-fitted when we train with a lot of data. \n",
    "\tThis happens when the model gets trained with so many inaccurate data entries and noise. \n",
    "\tOverfitting simply means high variance and low bias.\n",
    "\n",
    "\n",
    "\tOverfitting can be reduced by\n",
    "\n",
    "\t*Reducing model complexity\n",
    "\t*Increasing the training data\n",
    "\t*Ridge Regularization and Lasso Regularization\n",
    "\t*Using dropout for neural networks to tackle overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b8f43",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1a88e",
   "metadata": {},
   "source": [
    "## 6.Evaluate the model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef481669",
   "metadata": {},
   "source": [
    "\t-->Concluding the model with:\n",
    "\n",
    "\ta)Testing model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4af3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cmap1 = sns.diverging_palette(260,-10,s=50, l=75, n=5, as_cmap=True)\n",
    "plt.subplots(figsize=(12,8))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression assumption plots\n",
    "\n",
    "def get_plots(y_train,preditctions=results.fittedvalues):\n",
    "        f = plt.figure(figsize=(20,10))\n",
    "        ax = f.add_subplot(231)\n",
    "        sns.scatterplot(y_train,model.fittedvalues,ax=ax,color='r')\n",
    "        ax.set_title('Check for Linearity:\\n Actual Vs Predicted value')\n",
    "        \n",
    "        std_residuals = stats.zscore(y_train-results.fittedvalues)\n",
    "        f = plt.figure(figsize=(14,5))\n",
    "        ax = f.add_subplot(232)\n",
    "        sns.scatterplot(model.fittedvalues,std_residuals,ax=ax,color='g')\n",
    "        ax.set_title('Check for Linearity:\\n Predicted value Vs Std.Residuals')\n",
    "\n",
    "# Check for Residual normality & mean\n",
    "        ax = f.add_subplot(233)\n",
    "        sns.distplot((y_train - model.fittedvalues),ax=ax,color='b')\n",
    "        ax.axvline((y_train - model.fittedvalues).mean(),color='k',linestyle='--')\n",
    "        ax.set_title('Check for Residual normality & mean: \\n Residual eror');\n",
    "\n",
    "#Residuals - QQ Plot\n",
    "        sm.qqplot(model.resid, line='s')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "def residual_plots(results):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import statsmodels.formula.api as smf\n",
    "    from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "    from scipy import stats\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(2,2,figsize=(14,10))\n",
    "    ########## Residuals vs fitted  ##########\n",
    "    residuals = results.resid\n",
    "    fitted = results.fittedvalues\n",
    "    smoothed = lowess(residuals,fitted)\n",
    "    top3 = abs(residuals).sort_values(ascending = False)[:3]\n",
    "\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,7)\n",
    "    \n",
    "    ax[0,0].scatter(fitted, residuals, edgecolors = 'k', facecolors = 'none')\n",
    "    ax[0,0].plot(smoothed[:,0],smoothed[:,1],color = 'r')\n",
    "    ax[0,0].set_ylabel('Residuals')\n",
    "    ax[0,0].set_xlabel('Fitted Values')\n",
    "    ax[0,0].set_title('Residuals vs. Fitted')\n",
    "    ax[0,0].plot([min(fitted),max(fitted)],[0,0],color = 'k',linestyle = ':', alpha = .3)\n",
    "\n",
    "    for i in top3.index:\n",
    "        ax[0,0].annotate(i,xy=(fitted[i],residuals[i]))\n",
    "\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    ######### Normal qq plot ###########\n",
    "    sorted_student_residuals = pd.Series(results.get_influence().resid_studentized_internal)\n",
    "    sorted_student_residuals.index = results.resid.index\n",
    "    sorted_student_residuals = sorted_student_residuals.sort_values(ascending = True)\n",
    "    df = pd.DataFrame(sorted_student_residuals)\n",
    "    df.columns = ['sorted_student_residuals']\n",
    "    df['theoretical_quantiles'] = stats.probplot(df['sorted_student_residuals'], dist = 'norm', fit = False)[0]\n",
    "    rankings = abs(df['sorted_student_residuals']).sort_values(ascending = False)\n",
    "    top3 = rankings[:3]\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    x = df['theoretical_quantiles']\n",
    "    y = df['sorted_student_residuals']\n",
    "    ax[0,1].scatter(x,y, edgecolor = 'k',facecolor = 'none')\n",
    "    ax[0,1].set_title('Normal Q-Q')\n",
    "    ax[0,1].set_ylabel('Standardized Residuals')\n",
    "    ax[0,1].set_xlabel('Theoretical Quantiles')\n",
    "    ax[0,1].plot([np.min([x,y]),np.max([x,y])],[np.min([x,y]),np.max([x,y])], color = 'r', ls = '--')\n",
    "    for val in top3.index:\n",
    "        ax[0,1].annotate(val,xy=(df['theoretical_quantiles'].loc[val],df['sorted_student_residuals'].loc[val]))\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    ######### Homoscedasticity ############\n",
    "    student_residuals = results.get_influence().resid_studentized_internal\n",
    "    sqrt_student_residuals = pd.Series(np.sqrt(np.abs(student_residuals)))\n",
    "    sqrt_student_residuals.index = results.resid.index\n",
    "    smoothed = lowess(sqrt_student_residuals,fitted)\n",
    "    top3 = abs(sqrt_student_residuals).sort_values(ascending = False)[:3]\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    ax[1,0].scatter(fitted, sqrt_student_residuals, edgecolors = 'k', facecolors = 'none')\n",
    "    ax[1,0].plot(smoothed[:,0],smoothed[:,1],color = 'r')\n",
    "    ax[1,0].set_ylabel('$\\sqrt{|Studentized \\ Residuals|}$')\n",
    "    ax[1,0].set_xlabel('Fitted Values')\n",
    "    ax[1,0].set_title('Scale-Location')\n",
    "    ax[1,0].set_ylim(0,max(sqrt_student_residuals)+0.1)\n",
    "    for i in top3.index:\n",
    "        ax[1,0].annotate(i,xy=(fitted[i],sqrt_student_residuals[i]))\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    ######### Cooks distance  ###########\n",
    "    student_residuals = pd.Series(results.get_influence().resid_studentized_internal)\n",
    "    student_residuals.index = results.resid.index\n",
    "    df = pd.DataFrame(student_residuals)\n",
    "    df.columns = ['student_residuals']\n",
    "    df['leverage'] = results.get_influence().hat_matrix_diag\n",
    "    smoothed = lowess(df['student_residuals'],df['leverage'])\n",
    "    sorted_student_residuals = abs(df['student_residuals']).sort_values(ascending = False)\n",
    "    top3 = sorted_student_residuals[:3]\n",
    "\n",
    "    #fig, ax = plt.subplots()\n",
    "    x = df['leverage']\n",
    "    y = df['student_residuals']\n",
    "    xpos = max(x)+max(x)*0.01  \n",
    "    ax[1,1].scatter(x, y, edgecolors = 'k', facecolors = 'none')\n",
    "    ax[1,1].plot(smoothed[:,0],smoothed[:,1],color = 'r')\n",
    "    ax[1,1].set_ylabel('Studentized Residuals')\n",
    "    ax[1,1].set_xlabel('Leverage')\n",
    "    ax[1,1].set_title('Residuals vs. Leverage')\n",
    "    ax[1,1].set_ylim(min(y)-min(y)*0.15,max(y)+max(y)*0.15)\n",
    "    ax[1,1].set_xlim(-0.01,max(x)+max(x)*0.05)\n",
    "    plt.tight_layout()\n",
    "    for val in top3.index:\n",
    "        ax[1,1].annotate(val,xy=(x.loc[val],y.loc[val]))\n",
    "\n",
    "    cooksx = np.linspace(min(x), xpos, 50)\n",
    "    p = len(results.params)\n",
    "    poscooks1y = np.sqrt((p*(1-cooksx))/cooksx)\n",
    "    poscooks05y = np.sqrt(0.5*(p*(1-cooksx))/cooksx)\n",
    "    negcooks1y = -np.sqrt((p*(1-cooksx))/cooksx)\n",
    "    negcooks05y = -np.sqrt(0.5*(p*(1-cooksx))/cooksx)\n",
    "\n",
    "    ax[1,1].plot(cooksx,poscooks1y,label = \"Cook's Distance\", ls = ':', color = 'r')\n",
    "    ax[1,1].plot(cooksx,poscooks05y, ls = ':', color = 'r')\n",
    "    ax[1,1].plot(cooksx,negcooks1y, ls = ':', color = 'r')\n",
    "    ax[1,1].plot(cooksx,negcooks05y, ls = ':', color = 'r')\n",
    "    ax[1,1].plot([0,0],ax[1,1].get_ylim(), ls=\":\", alpha = .3, color = 'k')\n",
    "    ax[1,1].plot(ax[1,1].get_xlim(), [0,0], ls=\":\", alpha = .3, color = 'k')\n",
    "    ax[1,1].annotate('1.0', xy = (xpos, poscooks1y[-1]), color = 'r')\n",
    "    ax[1,1].annotate('0.5', xy = (xpos, poscooks05y[-1]), color = 'r')\n",
    "    ax[1,1].annotate('1.0', xy = (xpos, negcooks1y[-1]), color = 'r')\n",
    "    ax[1,1].annotate('0.5', xy = (xpos, negcooks05y[-1]), color = 'r')\n",
    "    ax[1,1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d418f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "58b837f9",
   "metadata": {},
   "source": [
    "\t\n",
    "    b)Evaluating the model performance using the RegMetrics (for regression problem) \n",
    "                                               or\n",
    "      Evaluating the model performance using the classification metrics (for classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b38b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "scores = pd.DataFrame(columns=['Model','MAE_Train','MSE_Train','RMSE_Train','MAPE_Train','MAE_Test','MSE_Test','RMSE_Test','MAPE_Test'])\n",
    "\n",
    "def get_metrics(train_act,train_pred,test_act,test_pred,model_description,dataframe):\n",
    "    MAE_Train = metrics.mean_absolute_error(train_act,train_pred)\n",
    "    MSE_Train = metrics.mean_squared_error(train_act,train_pred)\n",
    "    RMSE_Train = np.sqrt(metrics.mean_squared_error(train_act,train_pred))\n",
    "    MAPE_Train = mean_absolute_percentage_error(train_act,train_pred)\n",
    "    MAE_Test = metrics.mean_absolute_error(test_act,test_pred)\n",
    "    MSE_Test = metrics.mean_squared_error(test_act,test_pred)\n",
    "    RMSE_Test = np.sqrt(metrics.mean_squared_error(test_act,test_pred))\n",
    "    MAPE_Test = mean_absolute_percentage_error(test_act,test_pred)\n",
    "    dataframe = dataframe.append(pd.Series([model_description,MAE_Train,MSE_Train,RMSE_Train,MAPE_Train,MAE_Test,MSE_Test,RMSE_Test,MAPE_Test],\n",
    "                                           index=scores.columns ), ignore_index=True)\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfe198",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_metrics(y_train,model.predict(X_reg),y_test,model.predict(X_test_reg),\"Mult_reg\",scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification\n",
    "\n",
    "train_preds = logistic_model.predict(X_train)\n",
    "train_preds_prob=logistic_model.predict_proba(X_train)[:,1]\n",
    "test_preds = logistic_model.predict(X_test)\n",
    "test_preds_prob=logistic_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "confusion_matrix(y_train,train_preds)\n",
    "\n",
    "train_accuracy_1= accuracy_score(y_train,train_preds)\n",
    "train_recall_1= recall_score(y_train,train_preds)\n",
    "train_precision_1= precision_score(y_train,train_preds)\n",
    "\n",
    "test_accuracy_1= accuracy_score(y_test,test_preds)\n",
    "test_recall_1= recall_score(y_test,test_preds)\n",
    "test_precision_1= precision_score(y_test,test_preds)\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/top-10-model-evaluation-metrics-for-classification-ml-models-a0a0f1d51b9\n",
    "\n",
    "threshold = 0.5\n",
    "train_preds_prob = logit_model.predict(X_train)\n",
    "train_preds = np.where(train_preds_prob>threshold,1,0)\n",
    "\n",
    "test_preds_prob = logit_model.predict(X_test)\n",
    "test_preds = np.where(test_preds_prob>threshold,1,0)\n",
    "\n",
    "###### R-style logitmodel will predict the probability values and from those probabilities we will compute the classes , but in sklearn LogisticRegression  model.predict gives directly the classes not the probabilities\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "scores = pd.DataFrame(columns=['Model','Train_Accuracy','Train_Recall','Train_Precision','Train_F1_Score','Test_Accuracy','Test_Recall','Test_Precision','Test_F1_Score'])\n",
    "\n",
    "def get_metrics(train_actual,train_predicted,test_actual,test_predicted,model_description,dataframe):\n",
    "    train_accuracy = accuracy_score(train_actual,train_predicted)\n",
    "    train_recall   = recall_score(train_actual,train_predicted,average=\"weighted\")\n",
    "    train_precision= precision_score(train_actual,train_predicted,average=\"weighted\")\n",
    "    train_f1score  = f1_score(train_actual,train_predicted,average=\"weighted\")\n",
    "    test_accuracy = accuracy_score(test_actual,test_predicted)\n",
    "    test_recall   = recall_score(test_actual,test_predicted,average=\"weighted\")\n",
    "    test_precision= precision_score(test_actual,test_predicted,average=\"weighted\")\n",
    "    test_f1score  = f1_score(test_actual,test_predicted,average=\"weighted\")\n",
    "    dataframe = dataframe.append(pd.Series([model_description, train_accuracy,train_recall,train_precision,train_f1score,\n",
    "                                            test_accuracy,test_recall,test_precision,test_f1score],\n",
    "                                           index=scores.columns ), ignore_index=True)\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f28856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC And AUC\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_train, train_preds_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "%matplotlib notebook\n",
    "# plt.figure()\n",
    "plt.plot([0,1],[0,1],color='navy', lw=2, linestyle='--')\n",
    "plt.plot(fpr,tpr,color='orange', lw=3, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#### Manual inspection of threshold value\n",
    "\n",
    "roc_df = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':threshold})\n",
    "roc_df\n",
    "\n",
    "roc_df.sort_values('TPR',ascending=False,inplace=True)\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = threshold[optimal_idx]\n",
    "\n",
    "optimal_threshold\n",
    "\n",
    "custom_threshold = 0.099\n",
    "\n",
    "## To get in 0-1 format vector (pandas Series)\n",
    "final_pred_array = pd.Series([0 if x>custom_threshold else 1 for x in train_preds_prob])\n",
    "final_pred_array.value_counts()\n",
    "\n",
    "final_test_pred_array = pd.Series([0 if x>custom_threshold else 1 for x in test_preds_prob])\n",
    "final_test_pred_array.value_counts()\n",
    "\n",
    "## To get True-False format vector (pandas Series)\n",
    "final_pred = pd.Series(train_preds_prob > 0.099)\n",
    "print(final_pred.value_counts())\n",
    "final_test_pred=pd.Series(test_preds_prob > 0.099)\n",
    "print(final_test_pred.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017b8ed",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a2ed3",
   "metadata": {},
   "source": [
    "###### how to know that the model is good or not by looking at the errors\n",
    "        \n",
    "     ---> we check for mean and sd of the test dataset\n",
    "         (test.mean(),np.sqrt(test.var()) and compare the how far is the error from mean\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e4414",
   "metadata": {},
   "source": [
    "## 7.Hyperparameter tuning and trying with different models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13c1c429",
   "metadata": {},
   "source": [
    "    *Hyperparameter tuning is choosing a set of optimal hyperparameters for a learning algorithm.*\n",
    "    \n",
    "\tSome of the examples in model hyperparameters includes:\n",
    "    \n",
    "    -->C and sigma hyperparameters for support vector machines, \n",
    "    \n",
    "\t-->K in K-nearest neighbors, learning rate for training a neural network,\n",
    "    \n",
    "    -->the penalty in Logistic Regression Classifier. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 6)GridSearch - Hyper parameter Tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [2,5,7,10,12,15,20,24,27, 120, 100],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_leaf_nodes' : [5,10,12,20],\n",
    "    #'ccp_alpha' : [0.1,0.01,0.001,0.0001],\n",
    "    'class_weight' : ['balanced','None']\n",
    "}\n",
    "dt_gs = GridSearchCV(estimator= DecisionTreeClassifier(), \n",
    "                     param_grid= param_grid,\n",
    "                     cv = 3)\n",
    "dt_gs.fit(X_train, y_train)\n",
    "dt_gs.best_params_\n",
    "best_model = dt_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bcebb",
   "metadata": {},
   "source": [
    "****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb65f49",
   "metadata": {},
   "source": [
    "    \n",
    "## 8.Prediction or Inference."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4173266b",
   "metadata": {},
   "source": [
    "\tYou are now ready to use your Machine Learning model inferring results in real-life scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9893b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9142dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd317fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307121d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e306682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Decision Tree visualization\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "_ = tree.plot_tree(best_model, \n",
    "                   feature_names=X_train.columns,\n",
    "                   class_names=['<=50','>50'],\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42cc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aad68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c520e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c638e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4f334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786dda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fad72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
